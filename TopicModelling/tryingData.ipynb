{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from gensim.corpora import Dictionary\n",
    "# from gensim.models import TfidfModel, LdaModel\n",
    "from multiprocessing import Pool\n",
    "import sqlite3 as sql\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import time\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\INFO323\\\\TokenizedToast'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = 'Data\\enwiki-20170820.db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query(select, db=db):\n",
    "    '''\n",
    "    1. Connects to SQLite database (db)\n",
    "    2. Executes select statement\n",
    "    3. Return results and column names\n",
    "    \n",
    "    Input: 'select * from analytics limit 2'\n",
    "    Output: ([(1, 2, 3)], ['col_1', 'col_2', 'col_3'])\n",
    "    '''\n",
    "    with sql.connect(db) as conn:\n",
    "        c = conn.cursor()\n",
    "        c.execute(select)\n",
    "        col_names = [str(name[0]).lower() for name in c.description]\n",
    "    return c.fetchall(), col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text, lower=True):\n",
    "    '''\n",
    "    1. Strips apostrophes\n",
    "    2. Searches for all alpha tokens (exception for underscore)\n",
    "    3. Return list of tokens\n",
    "\n",
    "    Input: 'The 3 dogs jumped over Scott's tent!'\n",
    "    Output: ['the', 'dogs', 'jumped', 'over', 'scotts', 'tent']\n",
    "    '''\n",
    "    text = re.sub(\"'\", \"\", text)\n",
    "    if lower:\n",
    "        tokens = re.findall('''[a-z_]+''', text.lower())\n",
    "    else:\n",
    "        tokens = re.findall('''[A-Za-z_]''', text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article(article_id):\n",
    "    '''\n",
    "    1. Construct select statement\n",
    "    2. Retrieve all section_texts associated with article_id\n",
    "    3. Join section_texts into a single string (article_text)\n",
    "    4. Tokenize article_text\n",
    "    5. Return list of tokens\n",
    "    \n",
    "    Input: 100\n",
    "    Output: ['the','austroasiatic','languages','in',...]\n",
    "    '''\n",
    "    select = '''select section_text from articles where article_id=%d''' % article_id\n",
    "    docs, _ = get_query(select)\n",
    "    print(docs)\n",
    "    docs = [doc[0] for doc in docs]\n",
    "    doc = '\\n'.join(docs)\n",
    "    tokens = tokenize(doc)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Corpus():\n",
    "    def __init__(self, article_ids:list):\n",
    "        self.article_ids = article_ids\n",
    "        self.len = len(article_ids)\n",
    "\n",
    "    def __iter__(self):\n",
    "        article_ids = np.random.choice(self.article_ids, self.len, replace=False)\n",
    "        for doc in docs:\n",
    "            print(doc)\n",
    "            yield tfidf[dictionary.doc2bow(doc)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "select = '''select distinct article_id from articles'''\n",
    "article_ids, _ = get_query(select)\n",
    "article_ids = [article_id[0] for article_id in article_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_article_ids = np.random.choice(article_ids, 10, replace=False)\n",
    "docs = Corpus(sample_article_ids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5ee6f23f9c4d80c203dea4faa6a5d0c8cffa4ab65b221251ea7227320f350d1e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
